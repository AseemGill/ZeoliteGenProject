{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Import Packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import networkx as nx\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeoliteDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
    "        super(ZeoliteDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['ZeoGraphs.p', 'ZeoUnitCells.']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return os.listdir(self.processed_dir)\n",
    "    \n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        idx = 0\n",
    "        self.graphs = pd.read_pickle(self.raw_paths[0])\n",
    "        max_graph_size = 0\n",
    "        \n",
    "        for graph in self.graphs:\n",
    "            if max_graph_size < (graph.number_of_nodes()):\n",
    "                max_graph_size = (graph.number_of_nodes())\n",
    "                print(max_graph_size)\n",
    "\n",
    "        if  not os.listdir(self.processed_dir):\n",
    "            for graph in self.graphs:\n",
    "                # Read data from `raw_path\n",
    "                adj = torch.zeros((max_graph_size, max_graph_size),dtype=torch.int8)\n",
    "\n",
    "                graph_tmp = (torch.from_numpy(nx.to_numpy_array(graph)))\n",
    "                graph_tmp = graph_tmp.type(torch.int8)\n",
    "                adj = np.pad(graph_tmp, ((0, max_graph_size - graph_tmp.shape[1]), (0, max_graph_size - graph_tmp.shape[0])), \"constant\",constant_values = (0,0))\n",
    "                adj = torch.from_numpy(adj)\n",
    "\n",
    "\n",
    "                if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                    continue\n",
    "\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "\n",
    "                torch.save(adj, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "                idx += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
    "        return data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "16\n",
      "24\n",
      "32\n",
      "48\n",
      "72\n",
      "96\n",
      "144\n",
      "216\n",
      "252\n",
      "378\n",
      "432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = ZeoliteDataset(\"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m graphs \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mtest\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mraw\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mZeoGraphs.p\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m max_graph_size \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m graph \u001b[39min\u001b[39;00m graphs:\n",
      "File \u001b[1;32mc:\\Users\\GillA\\anaconda3\\envs\\ZeoliteGenProject_cuda\\lib\\site-packages\\pandas\\io\\pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    206\u001b[0m         \u001b[39m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mWarning\u001b[39;00m)\n\u001b[1;32m--> 208\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39;49mload(handles\u001b[39m.\u001b[39;49mhandle)\n\u001b[0;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m excs_to_catch:\n\u001b[0;32m    210\u001b[0m     \u001b[39m# e.g.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[39m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[39m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m pc\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graphs = pd.read_pickle(\"data\\\\test\\\\raw\\ZeoGraphs.p\")\n",
    "max_graph_size = 0\n",
    "\n",
    "for graph in graphs:\n",
    "    if max_graph_size < (graph.number_of_nodes()):\n",
    "        max_graph_size = (graph.number_of_nodes())\n",
    "        print(max_graph_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.CharTensor\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.zeros((100,100))\n",
    "print(x.type())\n",
    "\n",
    "y = x.type(torch.int8)\n",
    "print(y.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x281807fa610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([64, 432, 432])\n",
      "torch.Size([50, 432, 432])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for data in loader:\n",
    "    print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZeoliteGenProject_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
