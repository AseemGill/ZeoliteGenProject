{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import ase\n",
    "import os\n",
    "from ase.io import read\n",
    "import numpy as np\n",
    "import csv\n",
    "from ase.io.jsonio import read_json\n",
    "import json\n",
    "from scipy.stats import rankdata\n",
    "from ase.visualize import view\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader, Dataset, Data, InMemoryDataset\n",
    "from torch_geometric.utils import dense_to_sparse, degree, add_self_loops\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "import glob, os\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import trimesh\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_sort(matrix, threshold, neighbors, reverse=False, adj=False):\n",
    "    mask = matrix > threshold\n",
    "    distance_matrix_trimmed = np.ma.array(matrix, mask=mask)\n",
    "    if reverse == False:\n",
    "        distance_matrix_trimmed = rankdata(\n",
    "            distance_matrix_trimmed, method=\"ordinal\", axis=1\n",
    "        )\n",
    "    elif reverse == True:\n",
    "        distance_matrix_trimmed = rankdata(\n",
    "            distance_matrix_trimmed * -1, method=\"ordinal\", axis=1\n",
    "        )\n",
    "    distance_matrix_trimmed = np.nan_to_num(\n",
    "        np.where(mask, np.nan, distance_matrix_trimmed)\n",
    "    )\n",
    "    distance_matrix_trimmed[distance_matrix_trimmed > neighbors + 1] = 0\n",
    "\n",
    "    if adj == False:\n",
    "        distance_matrix_trimmed = np.where(\n",
    "            distance_matrix_trimmed == 0, distance_matrix_trimmed, matrix\n",
    "        )\n",
    "        return distance_matrix_trimmed\n",
    "    elif adj == True:\n",
    "        adj_list = np.zeros((matrix.shape[0], neighbors + 1))\n",
    "        adj_attr = np.zeros((matrix.shape[0], neighbors + 1))\n",
    "        for i in range(0, matrix.shape[0]):\n",
    "            temp = np.where(distance_matrix_trimmed[i] != 0)[0]\n",
    "            adj_list[i, :] = np.pad(\n",
    "                temp,\n",
    "                pad_width=(0, neighbors + 1 - len(temp)),\n",
    "                mode=\"constant\",\n",
    "                constant_values=0,\n",
    "            )\n",
    "            adj_attr[i, :] = matrix[i, adj_list[i, :].astype(int)]\n",
    "        distance_matrix_trimmed = np.where(\n",
    "            distance_matrix_trimmed == 0, distance_matrix_trimmed, matrix\n",
    "        )\n",
    "        return distance_matrix_trimmed, adj_list, adj_attr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 files\n",
      "================================================\n",
      "Processed 2000 files\n",
      "================================================\n",
      "Processed 3000 files\n",
      "================================================\n",
      "Processed 4000 files\n",
      "================================================\n",
      "Processed 5000 files\n",
      "================================================\n",
      "Processed 6000 files\n",
      "================================================\n",
      "Processed 7000 files\n",
      "================================================\n",
      "Processed 8000 files\n",
      "================================================\n",
      "Processed 9000 files\n",
      "================================================\n",
      "Processed 10000 files\n",
      "================================================\n",
      "Processed 11000 files\n",
      "================================================\n",
      "Processed 12000 files\n",
      "================================================\n",
      "Processed 13000 files\n",
      "================================================\n",
      "Processed 14000 files\n",
      "================================================\n",
      "Processed 15000 files\n",
      "================================================\n",
      "Processed 16000 files\n",
      "================================================\n",
      "Processed 17000 files\n",
      "================================================\n",
      "Processed 18000 files\n",
      "================================================\n",
      "Processed 19000 files\n",
      "================================================\n",
      "Processed 20000 files\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "# Loads MOFS Structure\n",
    "\n",
    "max_nodes = 20\n",
    "\n",
    "# os.chdir(\"./MOF_data\")\n",
    "mof_uc = []\n",
    "i = 1\n",
    "for file in glob.glob(\"C:\\\\Users\\\\GillA\\\\Desktop\\\\University\\\\PhD\\\\Projects\\\\Generation\\\\Zeolites\\\\qmof_database\\\\relaxed_structures\\\\*.cif\"): # List of Cifs of files --> glob.glob looks for .json or *<>\n",
    "    structure = ase.io.read(file) ### Relaxed Structure [No need for ]\n",
    "    distance_matrix = structure.get_all_distances(mic=True) \n",
    "    num_of_nodes = distance_matrix.shape[0]\n",
    "    if num_of_nodes <= max_nodes: # Only Files with less than 20 nodes\n",
    "        mof_uc.append(structure)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(\"Processed\", i, \"files\")\n",
    "        print(\"================================================\")\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0-th graph\n",
      "Processing 1-th graph\n",
      "Processing 2-th graph\n",
      "Processing 3-th graph\n",
      "Processing 4-th graph\n",
      "Processing 5-th graph\n",
      "Processing 6-th graph\n",
      "Processing 7-th graph\n",
      "Processing 8-th graph\n",
      "Processing 9-th graph\n",
      "Processing 10-th graph\n",
      "Processing 11-th graph\n",
      "Processing 12-th graph\n",
      "Processing 13-th graph\n"
     ]
    }
   ],
   "source": [
    "unit_cell = []\n",
    "mof_graph = []\n",
    "for i in range(len(mof_uc)):\n",
    "    print(\"Processing \",i,\"-th graph\", sep=\"\")\n",
    "    s1 = mof_uc[i]\n",
    "    distance_matrix = s1.get_all_distances(mic=True)\n",
    "    distance_matrix_trimmed = threshold_sort(distance_matrix,8,12,adj=False)\n",
    "    distance_matrix_trimmed = torch.Tensor(distance_matrix_trimmed)\n",
    "    distance_matrix_trimmed[distance_matrix_trimmed != 0] = 1\n",
    "    # graph_tmp = nx.convert_matrix.from_numpy_matrix(distance_matrix_trimmed.numpy())\n",
    "    mof_graph.extend([nx.convert_matrix.from_numpy_matrix(distance_matrix_trimmed.numpy())])\n",
    "    unit_cell.extend([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.928571428571427"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nu = [nx.number_of_nodes(g) for g in mof_graph]\n",
    "\n",
    "sum(nu)/len(nu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<networkx.classes.graph.Graph at 0x1286755b1f0>,\n",
       " <networkx.classes.graph.Graph at 0x1286755be50>,\n",
       " <networkx.classes.graph.Graph at 0x1286755bbb0>,\n",
       " <networkx.classes.graph.Graph at 0x128675495b0>,\n",
       " <networkx.classes.graph.Graph at 0x1282c49c220>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee4340>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee4460>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee42b0>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee4220>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee4040>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee42e0>,\n",
       " <networkx.classes.graph.Graph at 0x12867ee43a0>,\n",
       " <networkx.classes.graph.Graph at 0x128663a5be0>,\n",
       " <networkx.classes.graph.Graph at 0x128676c5eb0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ZeoliteGenProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
